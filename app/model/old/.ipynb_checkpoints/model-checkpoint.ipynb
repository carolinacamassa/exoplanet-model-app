{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://phl.upr.edu/projects/habitable-exoplanets-catalog/data/database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_NAME</th>\n",
       "      <th>P_STATUS</th>\n",
       "      <th>P_MASS</th>\n",
       "      <th>P_MASS_ERROR_MIN</th>\n",
       "      <th>P_MASS_ERROR_MAX</th>\n",
       "      <th>P_RADIUS</th>\n",
       "      <th>P_RADIUS_ERROR_MIN</th>\n",
       "      <th>P_RADIUS_ERROR_MAX</th>\n",
       "      <th>P_YEAR</th>\n",
       "      <th>P_UPDATED</th>\n",
       "      <th>...</th>\n",
       "      <th>P_HABZONE_CON</th>\n",
       "      <th>P_TYPE_TEMP</th>\n",
       "      <th>P_HABITABLE</th>\n",
       "      <th>P_ESI</th>\n",
       "      <th>S_CONSTELLATION</th>\n",
       "      <th>S_CONSTELLATION_ABR</th>\n",
       "      <th>S_CONSTELLATION_ENG</th>\n",
       "      <th>P_RADIUS_EST</th>\n",
       "      <th>P_MASS_EST</th>\n",
       "      <th>P_SEMI_MAJOR_AXIS_EST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 Com b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6165.86330</td>\n",
       "      <td>-476.74200</td>\n",
       "      <td>476.74200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>2014-05-14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hot</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083813</td>\n",
       "      <td>Coma Berenices</td>\n",
       "      <td>Com</td>\n",
       "      <td>Berenice's Hair</td>\n",
       "      <td>12.082709</td>\n",
       "      <td>6165.86330</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11 UMi b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4684.78480</td>\n",
       "      <td>-794.57001</td>\n",
       "      <td>794.57001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hot</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>Ursa Minor</td>\n",
       "      <td>UMi</td>\n",
       "      <td>Little Bear</td>\n",
       "      <td>12.229641</td>\n",
       "      <td>4684.78480</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14 And b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1525.57440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>2014-05-14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hot</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081917</td>\n",
       "      <td>Andromeda</td>\n",
       "      <td>And</td>\n",
       "      <td>Andromeda</td>\n",
       "      <td>12.848516</td>\n",
       "      <td>1525.57440</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14 Her b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1481.07850</td>\n",
       "      <td>-47.67420</td>\n",
       "      <td>47.67420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Cold</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145241</td>\n",
       "      <td>Hercules</td>\n",
       "      <td>Her</td>\n",
       "      <td>Hercules</td>\n",
       "      <td>12.865261</td>\n",
       "      <td>1481.07850</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16 Cyg B b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>565.73385</td>\n",
       "      <td>-25.42624</td>\n",
       "      <td>25.42624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996</td>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Warm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>Cygnus</td>\n",
       "      <td>Cyg</td>\n",
       "      <td>Swan</td>\n",
       "      <td>13.421749</td>\n",
       "      <td>565.73385</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       P_NAME  P_STATUS      P_MASS  P_MASS_ERROR_MIN  P_MASS_ERROR_MAX  \\\n",
       "0    11 Com b       3.0  6165.86330        -476.74200         476.74200   \n",
       "1    11 UMi b       3.0  4684.78480        -794.57001         794.57001   \n",
       "2    14 And b       3.0  1525.57440               NaN               NaN   \n",
       "3    14 Her b       3.0  1481.07850         -47.67420          47.67420   \n",
       "4  16 Cyg B b       3.0   565.73385         -25.42624          25.42624   \n",
       "\n",
       "   P_RADIUS  P_RADIUS_ERROR_MIN  P_RADIUS_ERROR_MAX  P_YEAR   P_UPDATED  ...  \\\n",
       "0       NaN                 NaN                 NaN    2007  2014-05-14  ...   \n",
       "1       NaN                 NaN                 NaN    2009  2018-09-06  ...   \n",
       "2       NaN                 NaN                 NaN    2008  2014-05-14  ...   \n",
       "3       NaN                 NaN                 NaN    2002  2018-09-06  ...   \n",
       "4       NaN                 NaN                 NaN    1996  2018-09-06  ...   \n",
       "\n",
       "   P_HABZONE_CON  P_TYPE_TEMP  P_HABITABLE     P_ESI  S_CONSTELLATION  \\\n",
       "0              0          Hot            0  0.083813   Coma Berenices   \n",
       "1              0          Hot            0  0.082414       Ursa Minor   \n",
       "2              0          Hot            0  0.081917        Andromeda   \n",
       "3              0         Cold            0  0.145241         Hercules   \n",
       "4              1         Warm            0  0.368627           Cygnus   \n",
       "\n",
       "   S_CONSTELLATION_ABR  S_CONSTELLATION_ENG  P_RADIUS_EST  P_MASS_EST  \\\n",
       "0                  Com      Berenice's Hair     12.082709  6165.86330   \n",
       "1                  UMi          Little Bear     12.229641  4684.78480   \n",
       "2                  And            Andromeda     12.848516  1525.57440   \n",
       "3                  Her             Hercules     12.865261  1481.07850   \n",
       "4                  Cyg                 Swan     13.421749   565.73385   \n",
       "\n",
       "   P_SEMI_MAJOR_AXIS_EST  \n",
       "0                   1.29  \n",
       "1                   1.53  \n",
       "2                   0.83  \n",
       "3                   2.93  \n",
       "4                   1.66  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets = pd.read_csv('data/phl_exoplanet_catalog.csv')\n",
    "planets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P_NAME' 'P_STATUS' 'P_MASS' 'P_MASS_ERROR_MIN' 'P_MASS_ERROR_MAX'\n",
      " 'P_RADIUS' 'P_RADIUS_ERROR_MIN' 'P_RADIUS_ERROR_MAX' 'P_YEAR' 'P_UPDATED'\n",
      " 'P_PERIOD' 'P_PERIOD_ERROR_MIN' 'P_PERIOD_ERROR_MAX' 'P_SEMI_MAJOR_AXIS'\n",
      " 'P_SEMI_MAJOR_AXIS_ERROR_MIN' 'P_SEMI_MAJOR_AXIS_ERROR_MAX'\n",
      " 'P_ECCENTRICITY' 'P_ECCENTRICITY_ERROR_MIN' 'P_ECCENTRICITY_ERROR_MAX'\n",
      " 'P_INCLINATION' 'P_INCLINATION_ERROR_MIN' 'P_INCLINATION_ERROR_MAX'\n",
      " 'P_OMEGA' 'P_OMEGA_ERROR_MIN' 'P_OMEGA_ERROR_MAX' 'P_TPERI'\n",
      " 'P_TPERI_ERROR_MIN' 'P_TPERI_ERROR_MAX' 'P_ANGULAR_DISTANCE'\n",
      " 'P_IMPACT_PARAMETER' 'P_IMPACT_PARAMETER_ERROR_MIN'\n",
      " 'P_IMPACT_PARAMETER_ERROR_MAX' 'P_TEMP_MEASURED' 'P_GEO_ALBEDO'\n",
      " 'P_GEO_ALBEDO_ERROR_MIN' 'P_GEO_ALBEDO_ERROR_MAX' 'P_DETECTION'\n",
      " 'P_DETECTION_MASS' 'P_DETECTION_RADIUS' 'P_ALT_NAMES' 'P_ATMOSPHERE'\n",
      " 'S_NAME' 'S_RA' 'S_DEC' 'S_MAG' 'S_DISTANCE' 'S_DISTANCE_ERROR_MIN'\n",
      " 'S_DISTANCE_ERROR_MAX' 'S_METALLICITY' 'S_METALLICITY_ERROR_MIN'\n",
      " 'S_METALLICITY_ERROR_MAX' 'S_MASS' 'S_MASS_ERROR_MIN' 'S_MASS_ERROR_MAX'\n",
      " 'S_RADIUS' 'S_RADIUS_ERROR_MIN' 'S_RADIUS_ERROR_MAX' 'S_TYPE' 'S_AGE'\n",
      " 'S_AGE_ERROR_MIN' 'S_AGE_ERROR_MAX' 'S_TEMPERATURE'\n",
      " 'S_TEMPERATURE_ERROR_MIN' 'S_TEMPERATURE_ERROR_MAX' 'S_DISC'\n",
      " 'S_MAGNETIC_FIELD' 'S_LOG_G' 'S_ALT_NAMES' 'P_ESCAPE' 'P_POTENTIAL'\n",
      " 'P_GRAVITY' 'P_DENSITY' 'P_HILL_SPHERE' 'P_DISTANCE' 'P_PERIASTRON'\n",
      " 'P_APASTRON' 'P_DISTANCE_EFF' 'P_FLUX' 'P_FLUX_MIN' 'P_FLUX_MAX'\n",
      " 'P_TEMP_EQUIL' 'P_TEMP_EQUIL_MIN' 'P_TEMP_EQUIL_MAX' 'P_TYPE'\n",
      " 'S_RADIUS_EST' 'S_TYPE_TEMP' 'S_RA_H' 'S_RA_T' 'S_DEC_T' 'S_LUMINOSITY'\n",
      " 'S_HZ_OPT_MIN' 'S_HZ_OPT_MAX' 'S_HZ_CON_MIN' 'S_HZ_CON_MAX'\n",
      " 'S_HZ_CON0_MIN' 'S_HZ_CON0_MAX' 'S_HZ_CON1_MIN' 'S_HZ_CON1_MAX'\n",
      " 'S_SNOW_LINE' 'S_ABIO_ZONE' 'S_TIDAL_LOCK' 'P_HABZONE_OPT'\n",
      " 'P_HABZONE_CON' 'P_TYPE_TEMP' 'P_HABITABLE' 'P_ESI' 'S_CONSTELLATION'\n",
      " 'S_CONSTELLATION_ABR' 'S_CONSTELLATION_ENG' 'P_RADIUS_EST' 'P_MASS_EST'\n",
      " 'P_SEMI_MAJOR_AXIS_EST']\n"
     ]
    }
   ],
   "source": [
    "# List of all columns\n",
    "print(planets.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    4048\n",
       "Name: P_STATUS, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets['P_STATUS'].value_counts()\n",
    "# All the planets have confirmed (=3) status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3993\n",
       "2      34\n",
       "1      21\n",
       "Name: P_HABITABLE, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets['P_HABITABLE'].value_counts()\n",
    "## 1 means conservatively considered habitable\n",
    "## 2 means optimistically considered habitable\n",
    "## 0 means not habitable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on the \"habitable\" column\n",
    "\n",
    "This column was defined in a counterintuitive way, in my opinion. If we have a scale that goes from \"not habitable\" to \"likely habitable\", with \"*maybe* habitable\" in the middle, then why does \"maybe habitable\" get the highest numerical value (2)? \n",
    "\n",
    "I will redefine it now so that we can use it as a target variable for our classification algorithm later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets['P_HABITABLE'] = planets['P_HABITABLE'].map( {0: 0, 1: 2, 2: 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts doesn't consider null values, so let's check \n",
    "# if there are unclassified planets, and drop them if they exist\n",
    "planets['P_HABITABLE'].isnull().sum()\n",
    "\n",
    "planets = planets.dropna(subset = ['P_HABITABLE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4048 entries, 0 to 4047\n",
      "Data columns (total 112 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   P_NAME                        4048 non-null   object \n",
      " 1   P_STATUS                      4048 non-null   float64\n",
      " 2   P_MASS                        1598 non-null   float64\n",
      " 3   P_MASS_ERROR_MIN              1467 non-null   float64\n",
      " 4   P_MASS_ERROR_MAX              1467 non-null   float64\n",
      " 5   P_RADIUS                      3139 non-null   float64\n",
      " 6   P_RADIUS_ERROR_MIN            3105 non-null   float64\n",
      " 7   P_RADIUS_ERROR_MAX            3105 non-null   float64\n",
      " 8   P_YEAR                        4048 non-null   int64  \n",
      " 9   P_UPDATED                     4048 non-null   object \n",
      " 10  P_PERIOD                      3938 non-null   float64\n",
      " 11  P_PERIOD_ERROR_MIN            3807 non-null   float64\n",
      " 12  P_PERIOD_ERROR_MAX            3807 non-null   float64\n",
      " 13  P_SEMI_MAJOR_AXIS             2367 non-null   float64\n",
      " 14  P_SEMI_MAJOR_AXIS_ERROR_MIN   1563 non-null   float64\n",
      " 15  P_SEMI_MAJOR_AXIS_ERROR_MAX   1564 non-null   float64\n",
      " 16  P_ECCENTRICITY                1380 non-null   float64\n",
      " 17  P_ECCENTRICITY_ERROR_MIN      971 non-null    float64\n",
      " 18  P_ECCENTRICITY_ERROR_MAX      971 non-null    float64\n",
      " 19  P_INCLINATION                 844 non-null    float64\n",
      " 20  P_INCLINATION_ERROR_MIN       812 non-null    float64\n",
      " 21  P_INCLINATION_ERROR_MAX       810 non-null    float64\n",
      " 22  P_OMEGA                       746 non-null    float64\n",
      " 23  P_OMEGA_ERROR_MIN             693 non-null    float64\n",
      " 24  P_OMEGA_ERROR_MAX             693 non-null    float64\n",
      " 25  P_TPERI                       481 non-null    float64\n",
      " 26  P_TPERI_ERROR_MIN             472 non-null    float64\n",
      " 27  P_TPERI_ERROR_MAX             472 non-null    float64\n",
      " 28  P_ANGULAR_DISTANCE            2361 non-null   float64\n",
      " 29  P_IMPACT_PARAMETER            1409 non-null   float64\n",
      " 30  P_IMPACT_PARAMETER_ERROR_MIN  1407 non-null   float64\n",
      " 31  P_IMPACT_PARAMETER_ERROR_MAX  1407 non-null   float64\n",
      " 32  P_TEMP_MEASURED               5 non-null      float64\n",
      " 33  P_GEO_ALBEDO                  0 non-null      float64\n",
      " 34  P_GEO_ALBEDO_ERROR_MIN        5 non-null      float64\n",
      " 35  P_GEO_ALBEDO_ERROR_MAX        5 non-null      float64\n",
      " 36  P_DETECTION                   4048 non-null   object \n",
      " 37  P_DETECTION_MASS              0 non-null      float64\n",
      " 38  P_DETECTION_RADIUS            0 non-null      float64\n",
      " 39  P_ALT_NAMES                   0 non-null      float64\n",
      " 40  P_ATMOSPHERE                  0 non-null      float64\n",
      " 41  S_NAME                        4048 non-null   object \n",
      " 42  S_RA                          4048 non-null   float64\n",
      " 43  S_DEC                         4048 non-null   float64\n",
      " 44  S_MAG                         3869 non-null   float64\n",
      " 45  S_DISTANCE                    4042 non-null   float64\n",
      " 46  S_DISTANCE_ERROR_MIN          3967 non-null   float64\n",
      " 47  S_DISTANCE_ERROR_MAX          3967 non-null   float64\n",
      " 48  S_METALLICITY                 2842 non-null   float64\n",
      " 49  S_METALLICITY_ERROR_MIN       2446 non-null   float64\n",
      " 50  S_METALLICITY_ERROR_MAX       2446 non-null   float64\n",
      " 51  S_MASS                        3283 non-null   float64\n",
      " 52  S_MASS_ERROR_MIN              3034 non-null   float64\n",
      " 53  S_MASS_ERROR_MAX              3063 non-null   float64\n",
      " 54  S_RADIUS                      3723 non-null   float64\n",
      " 55  S_RADIUS_ERROR_MIN            3576 non-null   float64\n",
      " 56  S_RADIUS_ERROR_MAX            3604 non-null   float64\n",
      " 57  S_TYPE                        1370 non-null   object \n",
      " 58  S_AGE                         2031 non-null   float64\n",
      " 59  S_AGE_ERROR_MIN               1887 non-null   float64\n",
      " 60  S_AGE_ERROR_MAX               1887 non-null   float64\n",
      " 61  S_TEMPERATURE                 3841 non-null   float64\n",
      " 62  S_TEMPERATURE_ERROR_MIN       3650 non-null   float64\n",
      " 63  S_TEMPERATURE_ERROR_MAX       3680 non-null   float64\n",
      " 64  S_DISC                        0 non-null      float64\n",
      " 65  S_MAGNETIC_FIELD              0 non-null      float64\n",
      " 66  S_LOG_G                       3575 non-null   float64\n",
      " 67  S_ALT_NAMES                   4048 non-null   object \n",
      " 68  P_ESCAPE                      706 non-null    float64\n",
      " 69  P_POTENTIAL                   706 non-null    float64\n",
      " 70  P_GRAVITY                     706 non-null    float64\n",
      " 71  P_DENSITY                     706 non-null    float64\n",
      " 72  P_HILL_SPHERE                 1546 non-null   float64\n",
      " 73  P_DISTANCE                    3978 non-null   float64\n",
      " 74  P_PERIASTRON                  3978 non-null   float64\n",
      " 75  P_APASTRON                    3978 non-null   float64\n",
      " 76  P_DISTANCE_EFF                3978 non-null   float64\n",
      " 77  P_FLUX                        3721 non-null   float64\n",
      " 78  P_FLUX_MIN                    3721 non-null   float64\n",
      " 79  P_FLUX_MAX                    3721 non-null   float64\n",
      " 80  P_TEMP_EQUIL                  3721 non-null   float64\n",
      " 81  P_TEMP_EQUIL_MIN              3721 non-null   float64\n",
      " 82  P_TEMP_EQUIL_MAX              3721 non-null   float64\n",
      " 83  P_TYPE                        4031 non-null   object \n",
      " 84  S_RADIUS_EST                  3844 non-null   float64\n",
      " 85  S_TYPE_TEMP                   3912 non-null   object \n",
      " 86  S_RA_H                        4048 non-null   float64\n",
      " 87  S_RA_T                        4048 non-null   object \n",
      " 88  S_DEC_T                       4048 non-null   object \n",
      " 89  S_LUMINOSITY                  3786 non-null   float64\n",
      " 90  S_HZ_OPT_MIN                  3786 non-null   float64\n",
      " 91  S_HZ_OPT_MAX                  3786 non-null   float64\n",
      " 92  S_HZ_CON_MIN                  3786 non-null   float64\n",
      " 93  S_HZ_CON_MAX                  3786 non-null   float64\n",
      " 94  S_HZ_CON0_MIN                 3786 non-null   float64\n",
      " 95  S_HZ_CON0_MAX                 3786 non-null   float64\n",
      " 96  S_HZ_CON1_MIN                 3786 non-null   float64\n",
      " 97  S_HZ_CON1_MAX                 3786 non-null   float64\n",
      " 98  S_SNOW_LINE                   3786 non-null   float64\n",
      " 99  S_ABIO_ZONE                   3083 non-null   float64\n",
      " 100 S_TIDAL_LOCK                  3281 non-null   float64\n",
      " 101 P_HABZONE_OPT                 4048 non-null   int64  \n",
      " 102 P_HABZONE_CON                 4048 non-null   int64  \n",
      " 103 P_TYPE_TEMP                   3721 non-null   object \n",
      " 104 P_HABITABLE                   4048 non-null   int64  \n",
      " 105 P_ESI                         3721 non-null   float64\n",
      " 106 S_CONSTELLATION               4048 non-null   object \n",
      " 107 S_CONSTELLATION_ABR           4048 non-null   object \n",
      " 108 S_CONSTELLATION_ENG           4048 non-null   object \n",
      " 109 P_RADIUS_EST                  4048 non-null   float64\n",
      " 110 P_MASS_EST                    4048 non-null   float64\n",
      " 111 P_SEMI_MAJOR_AXIS_EST         3978 non-null   float64\n",
      "dtypes: float64(94), int64(4), object(14)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# check null values and type per column\n",
    "planets.info(verbose = True, null_counts = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columms with more than 30% null values\n",
    "pl_data = planets[[column for column in planets if planets[column].count() / len(planets) >= 0.8]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3993\n",
       "1      34\n",
       "2      21\n",
       "Name: P_HABITABLE, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if we still have all the habitable planets\n",
    "pl_data['P_HABITABLE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all error columns\n",
    "pl_data = pl_data[[column for column in pl_data if (not 'MIN' in column) and (not 'MAX' in column)]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical values\n",
    "\n",
    "Some of the columns in the data have categorical values. Some of them are not relevant to our prediction goal, e.g. the type of detection that was used to find the exoplanet. A couple of them look useful though, so I will convert them to numerical columns now so we can keep them for further analysis; the rest I will just drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['P_NAME', 'P_YEAR', 'P_UPDATED', 'P_DETECTION', 'S_NAME', 'S_ALT_NAMES',\n",
       "       'P_TYPE', 'S_TYPE_TEMP', 'S_RA_T', 'S_DEC_T', 'P_HABZONE_OPT',\n",
       "       'P_HABZONE_CON', 'P_TYPE_TEMP', 'P_HABITABLE', 'S_CONSTELLATION',\n",
       "       'S_CONSTELLATION_ABR', 'S_CONSTELLATION_ENG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all non-numeric columns\n",
    "(pl_data.select_dtypes(exclude = ['float', 'int'])).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     P_TYPE_TEMP       P_TYPE S_TYPE_TEMP         S_RA_T         S_DEC_T\n",
      "2249         Hot    Neptunian           G  19 08 24.2650  +46 53 47.3172\n",
      "2034         Hot  Superterran           K  19 07 27.7186  +41 59 20.7096\n",
      "3922        Warm       Jovian           G  12 42 28.4990  -30 38 23.5320\n",
      "1522         Hot  Superterran           G  19 02 46.0817  +45 41 21.8256\n",
      "1329         Hot       Jovian           G  19 39 27.7249  +46 17 09.0744\n",
      "1675         Hot       Terran           G  19 22 58.6421  +43 15 38.7972\n",
      "2051         Hot    Neptunian           F  19 43 54.1371  +44 42 48.4020\n",
      "1025         Hot       Terran           G  03 53 04.6003  +17 54 25.4592\n",
      "2510         Hot    Neptunian           F  19 27 54.2857  +38 03 18.2700\n",
      "1145         Hot       Jovian           G  10 52 07.7840  +00 29 36.0672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Jovian         1302\n",
       "Superterran    1099\n",
       "Neptunian       898\n",
       "Terran          673\n",
       "Subterran        58\n",
       "Miniterran        1\n",
       "Name: P_TYPE, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out variables that look interesting\n",
    "print(pl_data[['P_TYPE_TEMP', 'P_TYPE','S_TYPE_TEMP', 'S_RA_T', 'S_DEC_T']].sample(10))\n",
    "# drop the rest\n",
    "pl_data['P_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we have a few categorical columns that are interesting and could be fun for the user to play around: **P_TYPE_TEMP, P_TYPE**. I think that the temperature column could simply be converted to a numerical scale since it's an ordered values, while we'll have to resort to *one-hot encoding* for the planet type.\n",
    "\n",
    "First, though, I'm going to check if any of the habitable planets have null values for these columns. In that case it would be better to not include these column further, since we have so few data for the habitable categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of null rows check\n",
    "\n",
    "## Planet temperature\n",
    "idx = pl_data['P_TYPE_TEMP'].isnull()\n",
    "print(pl_data[idx]['P_HABITABLE'].sum())\n",
    "\n",
    "## Planet type\n",
    "idx = pl_data['P_TYPE'].isnull()\n",
    "print(pl_data[idx]['P_HABITABLE'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, it seems that are no problems on that front. I'll just drop all the rows that have null values in these three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3716, 41)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_data = pl_data.loc[(pl_data['P_TYPE'].notnull()) & \n",
    "                      (pl_data['P_TYPE_TEMP'].notnull())]\n",
    "pl_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot     3338\n",
      "Warm     199\n",
      "Cold     179\n",
      "Name: P_TYPE_TEMP, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((pl_data['P_TYPE_TEMP']).value_counts())\n",
    "\n",
    "# Encoding temperatures categories as numbers\n",
    "temps = {'Hot': 3, 'Warm': 2, 'Cold': 1}\n",
    "\n",
    "pl_data['P_TEMP'] = pl_data['P_TYPE_TEMP'].map(temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_TEMP</th>\n",
       "      <th>P_TYPE_TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>2</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>3</td>\n",
       "      <td>Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>3</td>\n",
       "      <td>Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>2</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>2</td>\n",
       "      <td>Warm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3716 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      P_TEMP P_TYPE_TEMP\n",
       "0          3         Hot\n",
       "1          3         Hot\n",
       "2          3         Hot\n",
       "3          1        Cold\n",
       "4          2        Warm\n",
       "...      ...         ...\n",
       "4043       2        Warm\n",
       "4044       3         Hot\n",
       "4045       3         Hot\n",
       "4046       2        Warm\n",
       "4047       2        Warm\n",
       "\n",
       "[3716 rows x 2 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_data[['P_TEMP','P_TYPE_TEMP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for the planet type\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "types =  pl_data['P_TYPE'].unique()\n",
    "enc.fit(types.reshape(-1,1))\n",
    "new_rows =enc.transform(pl_data['P_TYPE'].values.reshape(-1,1)).toarray()\n",
    "new_columns = enc.get_feature_names(['P_TYPE'])\n",
    "\n",
    "\n",
    "pl_data = pd.concat([pl_data.reset_index(), pd.DataFrame(new_rows, columns = new_columns)],axis = 1).drop(['P_TYPE'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3716, 47)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which columns we are left with before reducing the number of features even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'P_NAME', 'P_STATUS', 'P_YEAR', 'P_UPDATED', 'P_PERIOD',\n",
       "       'P_DETECTION', 'S_NAME', 'S_RA', 'S_DEC', 'S_MAG', 'S_DISTANCE',\n",
       "       'S_MASS', 'S_RADIUS', 'S_TEMPERATURE', 'S_LOG_G', 'S_ALT_NAMES',\n",
       "       'P_DISTANCE', 'P_PERIASTRON', 'P_APASTRON', 'P_DISTANCE_EFF', 'P_FLUX',\n",
       "       'P_TEMP_EQUIL', 'S_RADIUS_EST', 'S_TYPE_TEMP', 'S_RA_H', 'S_RA_T',\n",
       "       'S_DEC_T', 'S_SNOW_LINE', 'S_TIDAL_LOCK', 'P_HABZONE_OPT',\n",
       "       'P_HABZONE_CON', 'P_TYPE_TEMP', 'P_HABITABLE', 'P_ESI',\n",
       "       'S_CONSTELLATION', 'S_CONSTELLATION_ABR', 'S_CONSTELLATION_ENG',\n",
       "       'P_RADIUS_EST', 'P_MASS_EST', 'P_SEMI_MAJOR_AXIS_EST', 'P_TEMP',\n",
       "       'P_TYPE_Jovian', 'P_TYPE_Neptunian', 'P_TYPE_Subterran',\n",
       "       'P_TYPE_Superterran', 'P_TYPE_Terran'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of my goals in building this model was to have just a few features that can be easily understood by the user of the app.\n",
    "By looking at descriptions for the columns that we have left (http://phl.upr.edu/projects/habitable-exoplanets-catalog/data/database Link), these seem to be the most interesting in our case:\n",
    "#### Planet data\n",
    "- *P_MASS_EST* - planet mass (earth masses)\n",
    "- *P_RADIUS_EST* - estimated planet radius (earth radii)\n",
    "- *P_PERIOD* - planet period (days)\n",
    "- *P_DISTANCE_EFF* - planet effective thermal distance from the star (AU)\n",
    "- And of course the P_TYPE categories and P_TEMP values we have worked on in the last section.\n",
    "\n",
    "\n",
    "#### Star data\n",
    "- *S_RADIUS_EST* - star radius estimated (solar units)\n",
    "- *S_MAG* - star magnitude\n",
    "- *S_MASS* - star mass (solar units)\n",
    "\n",
    "Let me remind you that our target variable is *P_HABITABLE*, that can takes the values 0, 1 or 2.\n",
    "\n",
    "Of course, this isn't the proper way to do feature selection, since I might have left out variables that have a strong impact on our prediction output, but we established at the beginning that we weren't following the proper way for this model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I select only the columns I want in the final training and testing data\n",
    "cols = np.concatenate((new_columns, ['P_MASS_EST','P_RADIUS_EST', 'P_PERIOD' , 'P_TEMP',\n",
    "                     'P_DISTANCE_EFF', 'S_RADIUS_EST', 'S_MAG','S_MASS', 'P_HABITABLE']))\n",
    "\n",
    "pl = pl_data[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null values (pt. 2)\n",
    "\n",
    "Now that we have a good sense of the features that we will use to train the model, let's check one last time for null values and decide how to deal with them. The overall reasoning will be:\n",
    "- drop the rows with null values if they do not belong to the habitable categories\n",
    "- either drop the column or fill the Null values if they appear in the 'habitable' planet rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_TYPE_Jovian           0\n",
       "P_TYPE_Neptunian        0\n",
       "P_TYPE_Subterran        0\n",
       "P_TYPE_Superterran      0\n",
       "P_TYPE_Terran           0\n",
       "P_MASS_EST              0\n",
       "P_RADIUS_EST            0\n",
       "P_PERIOD                9\n",
       "P_TEMP                  0\n",
       "P_DISTANCE_EFF          0\n",
       "S_RADIUS_EST            0\n",
       "S_MAG                  77\n",
       "S_MASS                685\n",
       "P_HABITABLE             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_TYPE_Jovian         0\n",
       "P_TYPE_Neptunian      0\n",
       "P_TYPE_Subterran      0\n",
       "P_TYPE_Superterran    0\n",
       "P_TYPE_Terran         0\n",
       "P_MASS_EST            0\n",
       "P_RADIUS_EST          0\n",
       "P_PERIOD              0\n",
       "P_TEMP                0\n",
       "P_DISTANCE_EFF        0\n",
       "S_RADIUS_EST          0\n",
       "S_MAG                 0\n",
       "S_MASS                3\n",
       "P_HABITABLE           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.loc[pl['P_HABITABLE'] > 0].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues found: \n",
    "- 77 not habitable rows are missing the 'star magnitude' value, and 7 of them the 'planet period' one. We can drop these rows\n",
    "- three of the 'habitable' planets ad 685 of the rest are missing the star mass value. I've decided to drop the entire column in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = pl.dropna(subset = ['S_MAG', 'P_PERIOD'])\n",
    "pl = pl.drop(['S_MASS'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_TYPE_Jovian         0\n",
       "P_TYPE_Neptunian      0\n",
       "P_TYPE_Subterran      0\n",
       "P_TYPE_Superterran    0\n",
       "P_TYPE_Terran         0\n",
       "P_MASS_EST            0\n",
       "P_RADIUS_EST          0\n",
       "P_PERIOD              0\n",
       "P_TEMP                0\n",
       "P_DISTANCE_EFF        0\n",
       "S_RADIUS_EST          0\n",
       "S_MAG                 0\n",
       "P_HABITABLE           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pl.drop(['P_HABITABLE'],axis = 1)\n",
    "y = pl['P_HABITABLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compensating class imbalance with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x183aa9db788>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(sampling_strategy = {2: 21, 1: 34, 0: 35}, random_state = 42)\n",
    "X_cc, y_cc = cc.fit_sample(X, y)\n",
    "\n",
    "X_cc['HABITABLE'] = y_cc\n",
    "X_cc['HABITABLE'].value_counts().plot(kind = 'bar', title = 'Count of habitable categories')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cc, y_cc, stratify=y_cc,\n",
    "                                    random_state=42, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rforest = RandomForestClassifier(n_estimators=30, random_state=123)\n",
    "rforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model's class predictions\n",
    "rf_predictions = rforest.predict(X_test)\n",
    "\n",
    "# Probabilities for each class\n",
    "rf_probs = rforest.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on test set: 1.0\n",
      "\n",
      "Class probabilities:\n",
      "Not habitable   Opt. Habitable   Cons. habitable\n",
      "[[0.         1.         0.        ]\n",
      " [0.         0.         1.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.06666667 0.93333333 0.        ]\n",
      " [0.96666667 0.         0.03333333]\n",
      " [1.         0.         0.        ]\n",
      " [0.         0.         1.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.96666667 0.         0.03333333]]\n",
      "\n",
      "Actual classes:\n",
      "[1 2 0 1 0 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Checking the results\n",
    "print('Model score on test set: ' + str(rforest.score(X_test, y_test)))\n",
    "\n",
    "print('\\nClass probabilities:\\n'+'Not habitable   Opt. Habitable   Cons. habitable')\n",
    "print(rf_probs)\n",
    "\n",
    "print('\\nActual classes:')\n",
    "print(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like our algorithm predicted correctly 100% of the classes. Of course, on such a small dataset, it's difficult to know if this would generalize well. \n",
    "There are better ways we could evaluate how the model actually performs, but for our purposes today we can just keep it as it is way and move on.\n",
    "\n",
    "The only thing I want to check before exporting our finished model is whether any of our features are redundant and can be dropped to simplify the app. The random forest classifier also outputs the relative **feature importance** (read [this article](https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e) if you want to know how that works)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_TYPE_Superterran</td>\n",
       "      <td>0.205917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P_RADIUS_EST</td>\n",
       "      <td>0.189452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HABITABLE</td>\n",
       "      <td>0.179824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P_MASS_EST</td>\n",
       "      <td>0.124820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_TYPE_Jovian</td>\n",
       "      <td>0.095199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S_RADIUS_EST</td>\n",
       "      <td>0.087910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P_PERIOD</td>\n",
       "      <td>0.050800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_TYPE_Terran</td>\n",
       "      <td>0.034429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S_MAG</td>\n",
       "      <td>0.018050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P_DISTANCE_EFF</td>\n",
       "      <td>0.013599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_TYPE_Neptunian</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_TYPE_Subterran</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P_TEMP</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "3   P_TYPE_Superterran    0.205917\n",
       "6         P_RADIUS_EST    0.189452\n",
       "12           HABITABLE    0.179824\n",
       "5           P_MASS_EST    0.124820\n",
       "0        P_TYPE_Jovian    0.095199\n",
       "10        S_RADIUS_EST    0.087910\n",
       "7             P_PERIOD    0.050800\n",
       "4        P_TYPE_Terran    0.034429\n",
       "11               S_MAG    0.018050\n",
       "9       P_DISTANCE_EFF    0.013599\n",
       "1     P_TYPE_Neptunian    0.000000\n",
       "2     P_TYPE_Subterran    0.000000\n",
       "8               P_TEMP    0.000000"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract feature importances from model\n",
    "f_imp = pd.DataFrame({'feature': list(X_train.columns),\n",
    "                   'importance': rforest.feature_importances_}).\\\n",
    "                    sort_values('importance', ascending = False)\n",
    "\n",
    "# Display\n",
    "f_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the planet temperature doesn't have any importance according to the random forest algorithm, so we'll drop this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop(['P_TEMP'],axis = 1)\n",
    "X_test = X_test.drop(['P_TEMP'],axis = 1)\n",
    "# Refitting the model\n",
    "rforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0 1 0 0 2 1 0]\n",
      "[1 2 0 1 0 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(rforest.predict(X_test))\n",
    "\n",
    "print(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our trained model needs to be exported in such a way that makes it available for the app to predict a result from the user's input.\n",
    "\n",
    "The python modules **pickle** and **joblib** can be both used to do this. What they do is *serialize* the input, which means translating it to a bit stream that can be stored on disk.\n",
    "The scikit-learn documentation recommends using joblib for serializing machine learning models, so we'll go with that one. Pickle works in a similar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(rforest, 'model.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a *'model.joblib'* file that contains our model translated to a bit stream. It can be translated back by using the load function, e.g. *load('model.joblib')*, and the app can then use it to predict the planet class for any test input we pass it.\n",
    "\n",
    "Before we wrap up the machine learning part of this project, one last thing: we need to know what are the constraints we will put on the user's input. To do that, we'll get some stats on the values of all the columns using pandas' *.describe()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_TYPE_Jovian</th>\n",
       "      <th>P_TYPE_Neptunian</th>\n",
       "      <th>P_TYPE_Subterran</th>\n",
       "      <th>P_TYPE_Superterran</th>\n",
       "      <th>P_TYPE_Terran</th>\n",
       "      <th>P_MASS_EST</th>\n",
       "      <th>P_RADIUS_EST</th>\n",
       "      <th>P_PERIOD</th>\n",
       "      <th>P_TEMP</th>\n",
       "      <th>P_DISTANCE_EFF</th>\n",
       "      <th>S_RADIUS_EST</th>\n",
       "      <th>S_MAG</th>\n",
       "      <th>P_HABITABLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "      <td>3632.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.292126</td>\n",
       "      <td>0.224945</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.176211</td>\n",
       "      <td>261.719015</td>\n",
       "      <td>5.275140</td>\n",
       "      <td>215.141387</td>\n",
       "      <td>2.854901</td>\n",
       "      <td>0.415376</td>\n",
       "      <td>1.560936</td>\n",
       "      <td>12.771594</td>\n",
       "      <td>0.020925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.454802</td>\n",
       "      <td>0.417604</td>\n",
       "      <td>0.123227</td>\n",
       "      <td>0.454424</td>\n",
       "      <td>0.381052</td>\n",
       "      <td>833.860892</td>\n",
       "      <td>5.145767</td>\n",
       "      <td>1137.581255</td>\n",
       "      <td>0.463047</td>\n",
       "      <td>1.076830</td>\n",
       "      <td>3.779245</td>\n",
       "      <td>2.891502</td>\n",
       "      <td>0.179053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037591</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.179715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.508922</td>\n",
       "      <td>1.670290</td>\n",
       "      <td>4.545523</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.052692</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>11.658250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.274964</td>\n",
       "      <td>2.567090</td>\n",
       "      <td>11.801013</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.098421</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>13.733000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.859081</td>\n",
       "      <td>10.059378</td>\n",
       "      <td>40.192694</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.225775</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>14.924000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17668.059000</td>\n",
       "      <td>39.795500</td>\n",
       "      <td>43500.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22.000001</td>\n",
       "      <td>71.230000</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P_TYPE_Jovian  P_TYPE_Neptunian  P_TYPE_Subterran  P_TYPE_Superterran  \\\n",
       "count    3632.000000       3632.000000       3632.000000         3632.000000   \n",
       "mean        0.292126          0.224945          0.015419            0.291300   \n",
       "std         0.454802          0.417604          0.123227            0.454424   \n",
       "min         0.000000          0.000000          0.000000            0.000000   \n",
       "25%         0.000000          0.000000          0.000000            0.000000   \n",
       "50%         0.000000          0.000000          0.000000            0.000000   \n",
       "75%         1.000000          0.000000          0.000000            1.000000   \n",
       "max         1.000000          1.000000          1.000000            1.000000   \n",
       "\n",
       "       P_TYPE_Terran    P_MASS_EST  P_RADIUS_EST      P_PERIOD       P_TEMP  \\\n",
       "count    3632.000000   3632.000000   3632.000000   3632.000000  3632.000000   \n",
       "mean        0.176211    261.719015      5.275140    215.141387     2.854901   \n",
       "std         0.381052    833.860892      5.145767   1137.581255     0.463047   \n",
       "min         0.000000      0.037591      0.336300      0.179715     1.000000   \n",
       "25%         0.000000      3.508922      1.670290      4.545523     3.000000   \n",
       "50%         0.000000      7.274964      2.567090     11.801013     3.000000   \n",
       "75%         0.000000     90.859081     10.059378     40.192694     3.000000   \n",
       "max         1.000000  17668.059000     39.795500  43500.000000     3.000000   \n",
       "\n",
       "       P_DISTANCE_EFF  S_RADIUS_EST        S_MAG  P_HABITABLE  \n",
       "count     3632.000000   3632.000000  3632.000000  3632.000000  \n",
       "mean         0.415376      1.560936    12.771594     0.020925  \n",
       "std          1.076830      3.779245     2.891502     0.179053  \n",
       "min          0.005800      0.110000     0.850000     0.000000  \n",
       "25%          0.052692      0.800000    11.658250     0.000000  \n",
       "50%          0.098421      0.970000    13.733000     0.000000  \n",
       "75%          0.225775      1.240000    14.924000     0.000000  \n",
       "max         22.000001     71.230000    18.800000     2.000000  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The machine learning part of this project is done.\n",
    "There's definitely room for improvement, and you are free to work a bit more on this notebook before moving on to the next fun part: building and connecting the Flask web app to the model.\n",
    "\n",
    "Once again, [here is the link] to the blog post that shows you how to do that. **Happy coding!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
